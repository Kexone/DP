\section{Experimenty}

Experimenty této práce probíhaly především na počítačích uvedených v předchozí kapitole. Nejprve je však vhodné zmínit konfiguraci daných počítačů:
\begin{itemize}
\item\textbf{HummingBoard Pro} - na tomto počítači je nainstalován Linux Debian 8.1 s označením ``jessie'' s grafickým rozhraním MATE 8.
\item\textbf{Banana PI} - na tomto počítači je nainstalován Linux Debian 8.1 s označením ``jessie'' s grafickým rozhraním Xfce 4.10. 
\item\textbf{Raspberry PI} - na tomto počítači je nainstalován Linux Raspbian. 
\end{itemize}

Dále pro srovnání výkonu těchto počítačů byl program otestován i na desktopovém počítači, na kterém byl i vyvíjen a odladěn. Jeho konfigurace zní: 
\begin{itemize}
\item\textit{Intel Core i7-6700k}, operační paměť  \textit{32 GB} a operační systém  \textit{Windows 10 Pro}.
\end{itemize}
Prvním sada experimentů byla detekce pomocí metodiky histogramu orientovaných hran a její zlepšení použítí substrakci pozadí při detekci ze statických kamer.

\subsection{Nalezení ideálního klasifikátoru}

Nalezení ideálního a spolehlivého klasifikátoru je klíčovou částí celého procesu, zároveň se jedná i o velmi komplikovaný a zdlouhavý úkol. Je důležité zvolit ideální tréninkovou sadu vzorků a k vzhledem zvoleného typu SVM a jejího jádra. Otestoval jsem kombinace $C$, $\nu$, $\varepsilon$-SVR klasifikátorové typy s lineárním a Gaussovým jádrem, přičemž jsem zjistil, že nejlepší kombinaci pro detekování chodců je kombinace typu $\varepsilon$-SVR s Gaussovým ($RBF$) jádrem, protože pozitivní detekce byla poměrně větší než falešná. Při zvolení správné kombinace je dalším krokem vybrat, jak už bylo zmíněno, tréninkovou sadu. Vyzkoušel jsem nejrůznější tréninkové sady dostupné na internetu a jejich kombinace.

Nejlepších výsledků jsem dosáhl s pozitivní trénovací sadou pana Dase \cite{sudipDas} a mou negativní sadou, která byla vytvořena z různých fotografií, které neobsahovaly žádnou osobu. Tyto sady jsou přiloženy v příloze této práce. Následujícím krokem je zvolení správných parametrů trénování klasifikátoru. Trénování klasifikátoru je velmi citlivé na tyto parametry, při změně některého z nich jen o tisícinu, můžeme dostat úplně jiný výsledek. Trénování klasifikátoru probíhalo dvakrát za sebou. Při druhém trénování se klasifikátor učil ze svých špatných detekcí, čemu se říká ``Bootstraping''. To znamená, že detekce se spustila na negativních vzorcích s tímto klasifikátorem a pokud detektor vrátil nějaký výsledek, byl zpět uložen do negativní sady a znovu natrénován, tento postup je ilustrován ve zdrojovém kódu \ref{src:double_train}.
\newpage

\begin{lstlisting}[label=src:double_train, language=cpp, caption=Bootstraping]
		cv::Size posSize = posSamplesLst[0].size();
		cv::HOGDescriptor myHog;
		myHog.winSize = posSize;
		std::vector < cv::Rect > locations;
		std::vector < float > hogDetector;
		
		getSvmDetector(svm, hogDetector);
		myHog.setSVMDetector(hogDetector);

		std::vector < cv::Rect > detections;

		for (size_t i = 0; i < negSamplesLst.size(); i++)	{
			myHog.detectMultiScale(negSamplesLst[i], detections);
			for (size_t j = 0; j < detections.size(); j++)	{
				cv::Mat detection = negSamplesLst[i](detections[j]).clone();
				resize(detection, detection, posSize);
				negSamplesLst.push_back(detection);
			}
		}
		labels.clear();
		labels.assign(posSamplesLst.size(), +1);
		labels.insert(labels.end(), negSamplesLst.size(), 0);

		gradientLst.clear();
		extractFeatures(posSamplesLst, gradientLst);
		extractFeatures(negSamplesLst, gradientLst);

		convertSamples2Mat(gradientLst, trainMat);
		trainSvm(trainMat, labels);
\end{lstlisting}

Natrénoval jsem klasifikátory s různými parametry a otestoval je na testovacích vzorcích. Tyto vzorky byly vyextrahované obrázky chodců a "ne-chodců" z testovacích videí pomocí jejich anotací a přiloženého nástroje pro tvorbu vzorků. Tento krok je v podstatě takovou první filtrací klasifikátoru, aby detekoval, co nejvíce chodců a nedetekoval oblasti, kde nejsou. Získal jsem xx klasifikátorů s různými parametry nastavení. Tyto klasifikátory jsem nadále filtroval pomocí ROC křivky \ref{} a vybral jeden z nich. Tyto klasifikátory a jejich trénovací nastavení jsou v tabulce \ref{}. 

Vybral jsem konfiguraci xx a s tímto klasifikátorem nakombinoval mixturu Gaussiánů a otestoval.






 První trénování --->špatný dataset
 druhé trénování --->špatné parametry
 třetí trénování --->téměř dobré
 čtvrté trénování -->ideální sada, ideální parametry, 85%
 
 dodatečné trénování na siluetách --> works


 testování --> dlib trvalo strašně dlouho 127h
 testování --> opencv trvalo strašně dlouho - rozšířené parametry


 kombinované trénování  extract features Hog  ->train dlib fhog
 trénování fhog -> čistě pos samples
 trénování hog ->neg/pos samples

